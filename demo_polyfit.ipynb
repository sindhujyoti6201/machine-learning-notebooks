{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sindhujyoti6201/machine-learning-notebooks/blob/main/demo_polyfit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Acknowledgement\n",
        "\n",
        "This lab is imported from prof. Christopher Musco's 2024 iteration of CS-GY 6923. Thanks Chris!"
      ],
      "metadata": {
        "id": "PC8OMFqh9kcW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vksyB1cjyMdZ"
      },
      "source": [
        "# Demo:  Polynomial Model Order Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coZt2-gIyMda"
      },
      "source": [
        "In this demo, we will illustrate the process of cross-validation for model order selection.  We demonstrate the concepts via  polynomial fitting using synthetic data.  The lab will demonstrate how to:\n",
        "* Characterize the model order for a simple polynomial model\n",
        "* Measure training and test error for a given model order\n",
        "* Select a suitable model order using cross-validation\n",
        "* Plot the results for the model order selection process\n",
        "\n",
        "We first load the packages as usual."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxIRNXYRyMda"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets, linear_model, preprocessing\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjU89_wJyMdb"
      },
      "source": [
        "## Polynomial Data\n",
        "\n",
        "To illustrate the concepts, we consider a simple polynomial model:\n",
        "$$\n",
        "   y = \\beta_0 + \\beta_1 x + \\cdots + \\beta_d x^d + \\epsilon,\n",
        "$$\n",
        "where $d$ is the polynomial degree.  We first generate *synthetic* data for this model.  Sythetic data means that the data was generated artifically (e.g. by a computer program) instead of being actually measured.    \n",
        "\n",
        "Our synthetic data is going to be generated via the following process:\n",
        "* Fix a degree 3 polynomial p. Below we choose $p(x) = 1 + .5x + 2x^3$\n",
        "* Draw each $x_i$ uniformly at random from $[-1,1]$.\n",
        "* For each $i$ set $y_i = p(x_i) + n_i$ where $n$ is a normal (Gaussian) random variable.\n",
        "\n",
        "As mentioned in class, working with polynomial regression problems can be difficult due to numerical stability issues. To avoid some headache, we are going to use a built in package instead of implementing our own regression algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLsEh7FWyMdb"
      },
      "outputs": [],
      "source": [
        "# Import useful polynomial library\n",
        "import numpy.polynomial.polynomial as poly\n",
        "\n",
        "# True model parameters\n",
        "beta = np.array([1,0.5,0,2])   # coefficients\n",
        "wstd = .5                     # noise\n",
        "dtrue = len(beta)-1            # true poly degree\n",
        "\n",
        "# Independent data\n",
        "nsamp = 100\n",
        "xdat = np.random.uniform(-1,1,nsamp)\n",
        "\n",
        "# Polynomial\n",
        "y0 = poly.polyval(xdat,beta)\n",
        "ydat = y0 + .5*np.random.normal(0,wstd,nsamp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVBMvBTKyMdc"
      },
      "source": [
        "If you were given the data, you would first plot the data via a scatter plot like this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXnkY-yryMdc"
      },
      "outputs": [],
      "source": [
        "plt.scatter(xdat,ydat)\n",
        "plt.xlim([-1,1])\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKE3YrQDyMdc"
      },
      "source": [
        "From this plot, you would have to find the relation $y \\approx f(x)$.  \n",
        "\n",
        "In this case, since the data was generated synthetically, we know \"true\" relation $y = p(x) + \\text{noise}$.    The code below plots the true relation on top of the scatter plot.  Of course, for \"real\" data, we would not know the true relation.  This is the advantage of synthetic data:  you can run a learning algorithm on the data and compare the estimated model to the true function.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1We11LUyMdd"
      },
      "outputs": [],
      "source": [
        "# Plot true function\n",
        "xp = np.linspace(-1,1,100)\n",
        "yp = poly.polyval(xp,beta)\n",
        "plt.xlim(-1,1)\n",
        "plt.plot(xp,yp,'r-',linewidth=2.0)\n",
        "\n",
        "# Plot the scatter plot of the measured data\n",
        "plt.scatter(xdat,ydat)\n",
        "plt.xlim([-1,1])\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.grid()\n",
        "plt.legend(['True (dtrue=3)', 'Data'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Wx2nc_VyMdd"
      },
      "source": [
        "## Fit Model of Different Model Orders\n",
        "\n",
        "First, suppose that we know the true model order  `d=3`, but then didn't know the coefficients of the model.\n",
        "As seen in class, we could do this with a data transformation and  multiple linear regression.\n",
        "\n",
        "Here we will instead use `sklearn`'s built in `polyfit` command. Again, we are doing this for numerical stability reason. While the method discussed in class works in theory, you need to be a bit careful when implementing it on a computer with finite precision arithmetic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxGAo8c3yMde"
      },
      "outputs": [],
      "source": [
        "d = 3\n",
        "beta_hat = poly.polyfit(xdat,ydat,d)\n",
        "\n",
        "# Plot true and estimated function\n",
        "xp = np.linspace(-1,1,100)\n",
        "yp = poly.polyval(xp,beta)\n",
        "yp_hat = poly.polyval(xp,beta_hat)\n",
        "plt.xlim(-1,1)\n",
        "plt.ylim(-1,3)\n",
        "plt.plot(xp,yp,'r-',linewidth=2)\n",
        "plt.plot(xp,yp_hat,'g-',linewidth=2)\n",
        "\n",
        "# Plot data\n",
        "plt.scatter(xdat,ydat)\n",
        "plt.legend(['True (dtrue=3)', 'Est (d=3)', 'Data'], loc='upper left')\n",
        "plt.grid()\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMe-oXLUyMde"
      },
      "source": [
        "We see we get an excellent fit to the true function.  \n",
        "\n",
        "But, in general, the model order `d` is not known.  So, it has to be estimated.   One idea is to use trial and error.  First, suppose we selected a model order that is too low, say $d=1$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uBmLr0FyMde"
      },
      "outputs": [],
      "source": [
        "d = 1\n",
        "beta_hat = poly.polyfit(xdat,ydat,d)\n",
        "\n",
        "# Plot true and estimated function\n",
        "xp = np.linspace(-1.2,1.2,100)\n",
        "yp = poly.polyval(xp,beta)\n",
        "yp_hat = poly.polyval(xp,beta_hat)\n",
        "plt.xlim(-1,1)\n",
        "plt.ylim(-1,3)\n",
        "plt.plot(xp,yp,'r-',linewidth=3)\n",
        "plt.plot(xp,yp_hat,'g-',linewidth=3)\n",
        "\n",
        "# Plot data\n",
        "plt.scatter(xdat,ydat)\n",
        "plt.legend(['True (dtrue=3)', 'Est (d=1)', 'Data'],loc='upper left')\n",
        "plt.grid()\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.xlim([-1.2,1.2])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGNVztUuyMdf"
      },
      "source": [
        "What we see is called *underfitting*.  The estimated function is not able to capture the full complexity of the relation between $x$ and $y$.  \n",
        "\n",
        "Now suppose that we tried a model that was very high, say $d=40$.\n",
        "\n",
        "**On your own:** Try out different values for the degree `d` here and see what happens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "J94wnuz8yMdf"
      },
      "outputs": [],
      "source": [
        "d = 40\n",
        "beta_hat = poly.polyfit(xdat,ydat,d)\n",
        "\n",
        "# Plot true and estimated function\n",
        "xp = np.linspace(-1.2,1.2,100)\n",
        "yp = poly.polyval(xp,beta)\n",
        "yp_hat = poly.polyval(xp,beta_hat)\n",
        "plt.xlim(-1.2,1.2)\n",
        "plt.ylim(-3,3)\n",
        "plt.plot(xp,yp,'r-',linewidth=3)\n",
        "plt.plot(xp,yp_hat,'g-',linewidth=3)\n",
        "\n",
        "# Plot data\n",
        "plt.scatter(xdat,ydat)\n",
        "plt.legend(['Est (d=40)', 'Data'],loc='upper left')\n",
        "plt.grid()\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.xlim([-1.2,1.2])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXeS7yRLyMdf"
      },
      "source": [
        "This is called *overfitting* and result is fitting the noise in the data and not the underlying relation $y=f(x)$.\n",
        "\n",
        "When we compare the estimated function with the true function we can see the overfitting and underfitting clearly.  But, in a real problem, we would not have access to the true function (otherwise, we wouldn't need to be estimating it).  The question then is if we can determine the correct model order from data.  \n",
        "\n",
        "One (bad) idea is for each model order to  measure the loss (here we use squared loss) on the training data and select $d$ that minimizes the loss.  To do this, the code below loops over a model order `d = 1,2,...,14` and for each model order, fits a model and measures the loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eumcEXLKyMdf"
      },
      "outputs": [],
      "source": [
        "dtest = np.arange(1,15)\n",
        "losstr = []\n",
        "for d in dtest:\n",
        "\n",
        "    # Fit data\n",
        "    beta_hat = poly.polyfit(xdat,ydat,d)\n",
        "\n",
        "    # Measure Loss on training data\n",
        "    yhat = poly.polyval(xdat,beta_hat)\n",
        "    lossd = np.sum((yhat-ydat)**2)\n",
        "    losstr.append(lossd)\n",
        "\n",
        "plt.plot(dtest,losstr,'o-')\n",
        "plt.xlabel('Polynomial degree (model complexity)')\n",
        "plt.ylabel('Squared Loss')\n",
        "plt.legend(['Train Loss'],loc='upper right')\n",
        "plt.grid()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0-zro3fyMdg"
      },
      "source": [
        "We see that minimizing the Loss on the training data doesn't work:  As we increase $d$, the Loss always decreases.  So minimizing loss on the training data leads to selecting a very high $d$ which in turn results in over-fitting.  How do we avoid this?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3jwfs68yMdg"
      },
      "source": [
        "## Using Cross-Validation\n",
        "\n",
        "One simple idea to avoid this issue is cross validation.  We split the data set into two components: (1) training and (2) test.  For now, let us split the data equally between the two parts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpIi0cuWyMdg"
      },
      "outputs": [],
      "source": [
        "# Number of samples for training and test\n",
        "ntr = nsamp // 2\n",
        "nts = nsamp - ntr\n",
        "\n",
        "# Training\n",
        "xtr = xdat[:ntr]\n",
        "ytr = ydat[:ntr]\n",
        "\n",
        "# Test\n",
        "xts = xdat[ntr:]\n",
        "yts = ydat[ntr:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXKhlRj9yMdg"
      },
      "source": [
        "Before we fit the data, let's plot the training and test samples separately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vn3Rj1rMyMdg"
      },
      "outputs": [],
      "source": [
        "# Plot true function\n",
        "xp = np.linspace(-1,1,100)\n",
        "yp = poly.polyval(xp,beta)\n",
        "plt.xlim(-1,1)\n",
        "plt.plot(xp,yp,'r-',linewidth=3)\n",
        "\n",
        "# Plot data\n",
        "plt.scatter(xtr,ytr)\n",
        "plt.scatter(xts,yts)\n",
        "plt.grid()\n",
        "plt.legend(['True','Training','Test'],loc='upper left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J_MY1YsyMdg"
      },
      "source": [
        "Now we perform *cross-validation*:  For each model order $d$, we:\n",
        "\n",
        "* Learn optimal parameters $\\hat{\\beta}$ of order $d$ on the training data\n",
        "* Measure $loss_{test}(d)$, the prediction error on the test data.\n",
        "\n",
        "Select $d$ that minimizes $loss_{test}(d)$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "Hhlf16pxyMdh"
      },
      "outputs": [],
      "source": [
        "dtest = np.arange(0,20)\n",
        "losstest = []\n",
        "losstr = []\n",
        "for d in dtest:\n",
        "\n",
        "    # Fit data\n",
        "    beta_hat = poly.polyfit(xtr,ytr,d)\n",
        "\n",
        "    # Measure squared loss on training data\n",
        "    # This is not necessary, but we do it just to show the training error\n",
        "    yhat = poly.polyval(xtr,beta_hat)\n",
        "    lossd = np.sum((yhat-ytr)**2)\n",
        "    losstr.append(lossd)\n",
        "\n",
        "    # Measure squared loss on test data\n",
        "    yhat = poly.polyval(xts,beta_hat)\n",
        "    lossd = np.sum((yhat-yts)**2)\n",
        "    losstest.append(lossd)\n",
        "\n",
        "plt.plot(dtest,losstr,'o-')\n",
        "plt.plot(dtest,losstest,'o-')\n",
        "plt.xlabel('Model order')\n",
        "plt.ylabel('Squared Loss')\n",
        "plt.grid()\n",
        "plt.legend(['Training','Test'],loc='upper right')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ykCLU3kyMdh"
      },
      "source": [
        "We select the model order from the minimum loss on the test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "LEHEIOovyMdh"
      },
      "outputs": [],
      "source": [
        "imin = np.argmin(losstest)\n",
        "print(\"Estimated model order= {0:d}\".format(dtest[imin]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euk5EuUnyMdh"
      },
      "source": [
        "As you can see, if we choose the model order too high (e.g. above roughly 15 degrees) the test grows.\n",
        "\n",
        "Note that the test loss actually looks relatively flat between 3 and 10ish. This may seem concerning -- what if the way things worked out (since there's randomness in our data), we chose a model of order 8 or 10 or 12 instead of 3?\n",
        "\n",
        "Well lets see. Let's try fitting a degree 10 model and plotting the results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "768JeS47yMdh"
      },
      "outputs": [],
      "source": [
        "d = 10\n",
        "beta_hat = poly.polyfit(xtr,ytr,d)\n",
        "\n",
        "# Plot true and estimated function\n",
        "xp = np.linspace(-1.2,1.2,100)\n",
        "yp = poly.polyval(xp,beta)\n",
        "yp_hat = poly.polyval(xp,beta_hat)\n",
        "plt.xlim(-1.2,1.2)\n",
        "plt.ylim(-3,3)\n",
        "\n",
        "# Plot data\n",
        "plt.plot(xp,yp,'r-',linewidth=3)\n",
        "plt.scatter(xtr,ytr)\n",
        "plt.scatter(xts,yts)\n",
        "plt.plot(xp,yp_hat,'g-',linewidth=3)\n",
        "plt.grid()\n",
        "plt.legend(['True','Training','Test', 'Model (d=10)'],loc='lower left')\n",
        "\n",
        "\n",
        "# plt.scatter(xdat,ydat)\n",
        "# plt.scatter(xts,yts)\n",
        "# plt.legend(['Data','Est (d=40)'],loc='upper left')\n",
        "# plt.grid()\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.xlim([-1.2,1.2])\n",
        "plt.ylim([-4,4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vn-IMOCyMdh"
      },
      "source": [
        "Even though we did not get the model order 'correct' and the fit degree $10$ polynomial may look slightly different than the true degree $3$ polynomial (especially near the edges of the interval, its still close enough that it will perform nearly as well in prediction for any future data examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "mNUuBhEpyMdh"
      },
      "source": [
        "## K-Fold Validation\n",
        "\n",
        "There are two potential problems with the simple training / test split in the past example.\n",
        "* We were only able to use a small number of samples (20 out of 40) for training the model\n",
        "* The particular model and model order selection depends heavily on the particular samples you chose for the training.\n",
        "\n",
        "Both of these issues are particularly problematic for data sets with small numbers of samples.  An improvement is to use k-fold validation.  In k-fold validation, we split the data into $k$ parts, each part being approximately equal in size.  In the example below, we will use $k=10$.  For each split, we fit the data on $k-1$ parts and test the data on the remaining part. Then, we average the score over the $k$ parts.  \n",
        "\n",
        "The `sklearn` package has many routines for this purpose.  We begin by importing the `model_selection` sub-package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jE4h38iMyMdh"
      },
      "outputs": [],
      "source": [
        "import  sklearn.model_selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99sV1mBOyMdh"
      },
      "source": [
        "Then, we run the model validation.  Note that $k$-fold validation can be computationally expensive since we need to iterate over all the folds, and for each fold, we need to iterate over all the model orders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1VhRKCOyMdi"
      },
      "outputs": [],
      "source": [
        "# Create a k-fold object\n",
        "nfold = 10\n",
        "kf = sklearn.model_selection.KFold(n_splits=nfold,shuffle=True)\n",
        "\n",
        "# Model orders to be tested\n",
        "dtest = np.arange(0,20)\n",
        "nd = len(dtest)\n",
        "\n",
        "lossts = np.zeros((nd,nfold))\n",
        "\n",
        "# Loop over the folds\n",
        "for isplit, Ind in enumerate(kf.split(xdat)):\n",
        "\n",
        "    # Get the training data in the split\n",
        "    Itr, Its = Ind\n",
        "    #kf.split( ) returns Ind, which contains the indices to the training and testing data for each fold\n",
        "    xtr = xdat[Itr]\n",
        "    ytr = ydat[Itr]\n",
        "    xts = xdat[Its]\n",
        "    yts = ydat[Its]\n",
        "\n",
        "    # Loop over the model order\n",
        "    for it, d in enumerate(dtest):\n",
        "\n",
        "        # Fit data on training data\n",
        "        beta_hat = poly.polyfit(xtr,ytr,d)\n",
        "\n",
        "        # Measure loss on test data\n",
        "        yhat = poly.polyval(xts,beta_hat)\n",
        "        lossts[it,isplit] = np.sum((yhat-yts)**2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1Tz329PyMdi"
      },
      "source": [
        "Now, we compute the mean loss over the folds for each model order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "RanFHL_zyMdi"
      },
      "outputs": [],
      "source": [
        "loss_mean = np.mean(lossts,axis=1) #note mean is taken over the second dimension, i.e. all folds for the same model order\n",
        "plt.plot(dtest, loss_mean, '-o')\n",
        "plt.xlabel('Model order')\n",
        "plt.ylabel('Test RSS')\n",
        "plt.grid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFbCkk8lyMdi"
      },
      "source": [
        "Again we check which model order achieves the minimum mean loss. For the polynomial problem we won't notice a huge difference in what model order is selected, but for some problems the k-fold cross validation ends up being much more reliable than simple train/test split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJYSw-VtyMdi"
      },
      "outputs": [],
      "source": [
        "imin = np.argmin(loss_mean)\n",
        "print(\"The selected model order is {0:d}\".format(dtest[imin]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H3IK_O4LCBV3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}